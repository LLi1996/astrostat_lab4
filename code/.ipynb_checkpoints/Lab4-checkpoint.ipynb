{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astrostat Lab4: model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryli/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119  HARPS points;  122  HIRES points\n",
      "Initial run of M0fix: chi2 = 395.796125725, 241 points\n",
      "Real M0 run: chi2 = 390.391712065, loglike = -567.778155919\n"
     ]
    }
   ],
   "source": [
    "# run the original notebook for M0fix and M0\n",
    "%run 'fit.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import erfinv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define BIC, AIC, reduced chi2, bayes factor functions\n",
    "\n",
    "def get_BIC(loglike, k, N):\n",
    "    \"\"\"calculates the BIC\n",
    "    Arguments:\n",
    "        loglike {float} -- log likelihood\n",
    "        k {int} -- number of parameters\n",
    "        N {int} -- number of data points\n",
    "    Return:\n",
    "        BIC {float} -- Bayesian Information Criterion\n",
    "    \"\"\"\n",
    "    BIC = k * np.log(N) - 2 * loglike\n",
    "    return BIC\n",
    "\n",
    "\n",
    "def get_AIC(loglike, k):\n",
    "    \"\"\"calculates the AIC\n",
    "    Arguments:\n",
    "        loglike {float} -- log likelihood\n",
    "        k {int} -- number of parameters\n",
    "    Return:\n",
    "        AIC {float} -- Akaike Information Criterion\n",
    "    \"\"\"\n",
    "    AIC = 2 * k - 2 * loglike\n",
    "    return AIC\n",
    "\n",
    "def get_reduced_chi2(chi2, k, N):\n",
    "    \"\"\"calculates the reduced chi2\n",
    "    Arguments:\n",
    "        chi2 {float} -- log likelihood\n",
    "        k {int} -- number of parameters\n",
    "        N {int} -- number of data points\n",
    "    Return:\n",
    "        reduced_chi2 {float}\n",
    "    \"\"\"\n",
    "    reduced_chi2 = chi2 / (N - k)\n",
    "    return reduced_chi2\n",
    "\n",
    "def get_bayes_factor(IC1, IC2):\n",
    "    \"\"\"calculates the bayes factor\n",
    "    Arguments:\n",
    "        IC1 {float} -- could be BIC or AIC for the first model\n",
    "        IC2 {float} -- could be BIC or AIC for the second model\n",
    "    return:\n",
    "        bayes_factor {float} -- is > 1 if IC1 < IC2\n",
    "    \"\"\"\n",
    "    bayes_factor = np.e ** (-.5 * (IC1 - IC2))\n",
    "    return bayes_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chi2 from model def\n",
    "def chi2_model(data, model, best_fit_params):\n",
    "    \"\"\"calculates chi2 based on model and best fit\n",
    "    Arguments:\n",
    "        data {np.ndarray} -- real data\n",
    "        model {function} -- model\n",
    "        best_fit_params {list} -- of best fit values, must match model input params\n",
    "    \"\"\"\n",
    "    chi2 = 0.0\n",
    "    for i in range(len(data)):\n",
    "        m_sol = model(data[i, 0], *best_fit_params)\n",
    "        chi2 = chi2 + ((data[i, 1] - m_sol) / data[i,2])**2\n",
    "    return chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M0fix & M0 (coded up in fix.ipynb): planets b c d e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# easy def for later use in CV\n",
    "param_bounds_m0fix = ([-2.*np.pi]*4, [2.*np.pi]*4)\n",
    "initial_guess_m0fix = [np.random.uniform(-np.pi,np.pi)]*4\n",
    "\n",
    "param_bounds_m0 = ([0.0,  Pb_sol-3.0*Pb_del, -2.0*np.pi,\n",
    "                    0.0,  Pc_sol-3.0*Pc_del, -2.0*np.pi,\n",
    "                    0.0,  Pd_sol-3.0*Pd_del, -2.0*np.pi,\n",
    "                    0.0,  Pe_sol-3.0*Pe_del, -2.0*np.pi],\n",
    "                   [20.0, Pb_sol+3.0*Pb_del,  2.0*np.pi,\n",
    "                    20.0, Pc_sol+3.0*Pc_del,  2.0*np.pi,\n",
    "                    20.0, Pd_sol+3.0*Pd_del,  2.0*np.pi,\n",
    "                    20.0, Pe_sol+3.0*Pe_del,  2.0*np.pi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m0_N = 119 + 122 # HARPS and HIRES datapoints\n",
    "m0_k = 12 # degrees of freedom\n",
    "m0_chi2 = 390.531407575 # from fit.ipynb run\n",
    "m0_loglike = -567.848003674 # from fit.ipynb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m0_AIC = get_AIC(m0_loglike, m0_k)\n",
    "m0_BIC = get_BIC(m0_loglike, m0_k, m0_N)\n",
    "m0_rchi2 = get_reduced_chi2(m0_chi2, m0_k, m0_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mffix & Mf: planets b c d e + f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 planet + f model with K & P fixed to Vogt+ reported values\n",
    "def Mffix(t, qb, qc, qd, qe, qf):\n",
    "    return Kb_sol*np.sin(2.0*np.pi*t/Pb_sol+qb)\\\n",
    "           + Kc_sol*np.sin(2.0*np.pi*t/Pc_sol+qc)\\\n",
    "           + Kd_sol*np.sin(2.0*np.pi*t/Pd_sol+qd)\\\n",
    "           + Ke_sol*np.sin(2.0*np.pi*t/Pe_sol+qe)\\\n",
    "           + Kf_sol*np.sin(2.0*np.pi*t/Pf_sol+qf)\n",
    "\n",
    "# 4 planet + f full model\n",
    "def Mf(t, Kb, Pb, qb, Kc, Pc, qc, Kd, Pd, qd, Ke, Pe, qe, Kf, Pf, qf):\n",
    "    return Kb*np.sin(2.0*np.pi*t/Pb+qb)\\\n",
    "           + Kc*np.sin(2.0*np.pi*t/Pc+qc)\\\n",
    "           + Kd*np.sin(2.0*np.pi*t/Pd+qd)\\\n",
    "           + Ke*np.sin(2.0*np.pi*t/Pe+qe)\\\n",
    "           + Kf*np.sin(2.0*np.pi*t/Pf+qf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mffix\n",
    "param_bounds_mffix = ([-2.*np.pi]*5, [2.*np.pi]*5)\n",
    "\n",
    "initial_guess_mffix = [np.random.uniform(-np.pi,np.pi)]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mffix: chi2 = 349.597443429, 241 points\n"
     ]
    }
   ],
   "source": [
    "# fit Mffix and get best fitting parameters and chi2\n",
    "Mffix_best, Mffix_cov = curve_fit(Mffix, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                                  p0=initial_guess_mffix, bounds=param_bounds_mffix)\n",
    "\n",
    "# Get the chi2\n",
    "mffix_chi2 = chi2_model(data, Mffix, Mffix_best)\n",
    "\n",
    "# Print output\n",
    "print('Mffix: chi2 = {0}, {1} points'.format(mffix_chi2,len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting phase solutions as initial guesses for Mf\n",
    "qb_sol_mffix, qc_sol_mffix, qd_sol_mffix, qe_sol_mffix, qf_sol_mffix = Mffix_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mf, first four bounds same as m0\n",
    "param_bounds_mf = (param_bounds_m0[0] + [0.0,  Pf_sol-3.0*Pf_del, -2.0*np.pi],\n",
    "                   param_bounds_m0[1] + [20.0, Pf_sol+3.0*Pf_del,  2.0*np.pi])\n",
    "\n",
    "# mffix results as inputs\n",
    "initial_guess_mf = [Kb_sol, Pb_sol, qb_sol_mffix,\n",
    "                    Kc_sol, Pc_sol, qc_sol_mffix,\n",
    "                    Kd_sol, Pd_sol, qd_sol_mffix,\n",
    "                    Ke_sol, Pe_sol, qe_sol_mffix,\n",
    "                    Kf_sol, Pf_sol, qf_sol_mffix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mf run: chi2 = 345.498471424, loglike = -545.331535598\n"
     ]
    }
   ],
   "source": [
    "# fit Mf and get best fitting parameters and chi2 and loglike\n",
    "Mf_best, Mf_cov = curve_fit(Mf, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                            p0=initial_guess_mf, bounds=param_bounds_mf)\n",
    "\n",
    "# Get the chi2\n",
    "mf_chi2 = chi2_model(data, Mf, Mf_best)\n",
    "\n",
    "# Get the loglike\n",
    "mf_loglike = -0.5*len(data)*np.log(2.0*np.pi) - np.sum(np.log(data[:,2])) - 0.5*mf_chi2\n",
    "\n",
    "# Print output\n",
    "print('Mf run: chi2 = {0}, loglike = {1}'.format(mf_chi2,mf_loglike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AIC, BIC, reduced chi2 for Mf\n",
    "mf_N = m0_N # same number of datapoints\n",
    "mf_k = 15 # degrees of freedom\n",
    "\n",
    "mf_AIC = get_AIC(mf_loglike, mf_k)\n",
    "mf_BIC = get_BIC(mf_loglike, mf_k, mf_N)\n",
    "mf_rchi2 = get_reduced_chi2(mf_chi2, mf_k, mf_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mgfix & Mg: planets b c d e + g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 planet + g model with K & P fixed to Vogt+ reported values\n",
    "def Mgfix(t, qb, qc, qd, qe, qg):\n",
    "    return Kb_sol*np.sin(2.0*np.pi*t/Pb_sol+qb)\\\n",
    "           + Kc_sol*np.sin(2.0*np.pi*t/Pc_sol+qc)\\\n",
    "           + Kd_sol*np.sin(2.0*np.pi*t/Pd_sol+qd)\\\n",
    "           + Ke_sol*np.sin(2.0*np.pi*t/Pe_sol+qe)\\\n",
    "           + Kg_sol*np.sin(2.0*np.pi*t/Pg_sol+qg)\n",
    "\n",
    "# 4 planet + g full model\n",
    "# in reality this is the same model as Mf (a 4 sinusoid with no fixed parameters)\n",
    "def Mg(t, Kb, Pb, qb, Kc, Pc, qc, Kd, Pd, qd, Ke, Pe, qe, Kg, Pg, qg):\n",
    "    return Mf(t, Kb, Pb, qb, Kc, Pc, qc, Kd, Pd, qd, Ke, Pe, qe, Kg, Pg, qg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mffix\n",
    "param_bounds_mgfix = ([-2.*np.pi]*5, [2.*np.pi]*5)\n",
    "\n",
    "initial_guess_mgfix = [np.random.uniform(-np.pi,np.pi)]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mgfix: chi2 = 347.861935825, 241 points\n"
     ]
    }
   ],
   "source": [
    "# fit Mffix and get best fitting parameters and chi2\n",
    "Mgfix_best, Mgfix_cov = curve_fit(Mgfix, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                                  p0=initial_guess_mgfix, bounds=param_bounds_mgfix)\n",
    "\n",
    "# Get the chi2\n",
    "mgfix_chi2 = chi2_model(data, Mgfix, Mgfix_best)\n",
    "\n",
    "# Print output\n",
    "print('Mgfix: chi2 = {0}, {1} points'.format(mgfix_chi2,len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting phase solutions as initial guesses for Mg\n",
    "qb_sol_mgfix, qc_sol_mgfix, qd_sol_mgfix, qe_sol_mgfix, qg_sol_mgfix = Mgfix_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mg\n",
    "# the first 4 bounds are the same as for M0\n",
    "param_bounds_mg = (param_bounds_m0[0] + [0.0, Pg_sol-3.0*Pg_del, -2.0*np.pi],\n",
    "                   param_bounds_m0[1] + [20.0, Pg_sol+3.0*Pg_del,  2.0*np.pi])\n",
    "\n",
    "# mgfix results as inputs\n",
    "initial_guess_mg = [Kb_sol, Pb_sol, qb_sol_mgfix,\n",
    "                    Kc_sol, Pc_sol, qc_sol_mgfix,\n",
    "                    Kd_sol, Pd_sol, qd_sol_mgfix,\n",
    "                    Ke_sol, Pe_sol, qe_sol_mgfix,\n",
    "                    Kg_sol, Pg_sol, qg_sol_mgfix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mg run: chi2 = 341.941846542, loglike = -543.553223157\n"
     ]
    }
   ],
   "source": [
    "# fit Mg and get best fitting parameters and chi2 and loglike\n",
    "Mg_best, Mg_cov = curve_fit(Mg, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                            p0=initial_guess_mg, bounds=param_bounds_mg)\n",
    "\n",
    "# Get the chi2\n",
    "mg_chi2 = chi2_model(data, Mg, Mg_best)\n",
    "\n",
    "# Get the loglike\n",
    "mg_loglike = -0.5*len(data)*np.log(2.0*np.pi) - np.sum(np.log(data[:,2])) - 0.5*mg_chi2\n",
    "\n",
    "# Print output\n",
    "print('Mg run: chi2 = {0}, loglike = {1}'.format(mg_chi2, mg_loglike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AIC, BIC, reduced chi2 for Mg\n",
    "mg_N = m0_N # same number of datapoints\n",
    "mg_k = 15 # degrees of freedom\n",
    "\n",
    "mg_AIC = get_AIC(mg_loglike, mg_k)\n",
    "mg_BIC = get_BIC(mg_loglike, mg_k, mg_N)\n",
    "mg_rchi2 = get_reduced_chi2(mg_chi2, mg_k, mg_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mfgfix & Mfg: planets b c d e + f&g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 planet + f + g model with K & P fixed to Vogt+ reported values\n",
    "def Mfgfix(t, qb, qc, qd, qe, qf, qg):\n",
    "    return Kb_sol*np.sin(2.0*np.pi*t/Pb_sol+qb)\\\n",
    "           + Kc_sol*np.sin(2.0*np.pi*t/Pc_sol+qc)\\\n",
    "           + Kd_sol*np.sin(2.0*np.pi*t/Pd_sol+qd)\\\n",
    "           + Ke_sol*np.sin(2.0*np.pi*t/Pe_sol+qe)\\\n",
    "           + Kf_sol*np.sin(2.0*np.pi*t/Pf_sol+qf)\\\n",
    "           + Kg_sol*np.sin(2.0*np.pi*t/Pg_sol+qg)\n",
    "\n",
    "# 4 planet + f + g full model\n",
    "def Mfg(t, Kb, Pb, qb, Kc, Pc, qc, Kd, Pd, qd, Ke, Pe, qe, Kf, Pf, qf, Kg, Pg, qg):\n",
    "    return Kb*np.sin(2.0*np.pi*t/Pb+qb)\\\n",
    "           + Kc*np.sin(2.0*np.pi*t/Pc+qc)\\\n",
    "           + Kd*np.sin(2.0*np.pi*t/Pd+qd)\\\n",
    "           + Ke*np.sin(2.0*np.pi*t/Pe+qe)\\\n",
    "           + Kf*np.sin(2.0*np.pi*t/Pf+qf)\\\n",
    "           + Kg*np.sin(2.0*np.pi*t/Pg+qg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mfgfix\n",
    "param_bounds_mfgfix = ([-2.*np.pi]*6, [2.*np.pi]*6)\n",
    "\n",
    "initial_guess_mfgfix = [np.random.uniform(-np.pi,np.pi)]*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mfgfix: chi2 = 302.861634452, 241 points\n"
     ]
    }
   ],
   "source": [
    "# fit Mfgfix and get best fitting parameters and chi2\n",
    "Mfgfix_best, Mfgfix_cov = curve_fit(Mfgfix, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                                  p0=initial_guess_mfgfix, bounds=param_bounds_mfgfix)\n",
    "\n",
    "# Get the chi2\n",
    "mfgfix_chi2 = chi2_model(data, Mfgfix, Mfgfix_best)\n",
    "\n",
    "# Print output\n",
    "print('Mfgfix: chi2 = {0}, {1} points'.format(mfgfix_chi2,len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting phase solutions as initial guesses for Mfg\n",
    "qb_sol_mfgfix, qc_sol_mfgfix, qd_sol_mfgfix, qe_sol_mfgfix, qf_sol_mfgfix, qg_sol_mfgfix = Mfgfix_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mfg\n",
    "# the first 5 bounds are the same as for Mf\n",
    "param_bounds_mfg = (param_bounds_mf[0] + [0.0, Pg_sol-3.0*Pg_del, -2.0*np.pi],\n",
    "                   param_bounds_mf[1] + [20.0, Pg_sol+3.0*Pg_del,  2.0*np.pi])\n",
    "\n",
    "# mgfix results as inputs\n",
    "initial_guess_mfg = [Kb_sol, Pb_sol, qb_sol_mfgfix,\n",
    "                    Kc_sol, Pc_sol, qc_sol_mfgfix,\n",
    "                    Kd_sol, Pd_sol, qd_sol_mfgfix,\n",
    "                    Ke_sol, Pe_sol, qe_sol_mfgfix,\n",
    "                    Kf_sol, Pf_sol, qf_sol_mfgfix,\n",
    "                    Kg_sol, Pg_sol, qg_sol_mfgfix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mg run: chi2 = 297.536671208, loglike = -521.35063549\n"
     ]
    }
   ],
   "source": [
    "# fit Mg and get best fitting parameters and chi2 and loglike\n",
    "Mfg_best, Mfg_cov = curve_fit(Mfg, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                              p0=initial_guess_mfg, bounds=param_bounds_mfg)\n",
    "\n",
    "# Get the chi2\n",
    "mfg_chi2 = chi2_model(data, Mfg, Mfg_best)\n",
    "\n",
    "# Get the loglike\n",
    "mfg_loglike = -0.5*len(data)*np.log(2.0*np.pi) - np.sum(np.log(data[:,2])) - 0.5*mfg_chi2\n",
    "\n",
    "# Print output\n",
    "print('Mg run: chi2 = {0}, loglike = {1}'.format(mfg_chi2, mfg_loglike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AIC, BIC, reduced chi2 for Mfg\n",
    "mfg_N = m0_N # same number of datapoints\n",
    "mfg_k = 18 # degrees of freedom\n",
    "\n",
    "mfg_AIC = get_AIC(mfg_loglike, mfg_k)\n",
    "mfg_BIC = get_BIC(mfg_loglike, mfg_k, mfg_N)\n",
    "mfg_rchi2 = get_reduced_chi2(mfg_chi2, mfg_k, mfg_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Simple model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2:\n",
      "\tM0: 390.531407575 \tMf: 345.498471424 \tMg: 341.941846542 \tMfg: 297.536671208\n",
      "Reduced chi2:\n",
      "\tM0: 1.70537732566 \tMf: 1.52875429834 \tMg: 1.5130170201 \tMfg: 1.33424516237\n",
      "BIC:\n",
      "\tM0: 1201.51357055 \tMf: 1172.9350252 \tMg: 1169.37840032 \tMfg: 1141.42761578\n",
      "AIC:\n",
      "\tM0: 1159.69600735 \tMf: 1120.6630712 \tMg: 1117.10644631 \tMfg: 1078.70127098\n",
      "\n",
      "Chi2 and reduced chi2 do go down as we go to more complex models, but are they really better?\n"
     ]
    }
   ],
   "source": [
    "# looking at results\n",
    "print('Chi2:\\n\\tM0: {0} \\tMf: {1} \\tMg: {2} \\tMfg: {3}'\n",
    "      .format(m0_chi2, mf_chi2, mg_chi2, mfg_chi2))\n",
    "print('Reduced chi2:\\n\\tM0: {0} \\tMf: {1} \\tMg: {2} \\tMfg: {3}'\n",
    "      .format(m0_rchi2, mf_rchi2, mg_rchi2, mfg_rchi2))\n",
    "print('BIC:\\n\\tM0: {0} \\tMf: {1} \\tMg: {2} \\tMfg: {3}'\n",
    "      .format(m0_BIC, mf_BIC, mg_BIC, mfg_BIC))\n",
    "print('AIC:\\n\\tM0: {0} \\tMf: {1} \\tMg: {2} \\tMfg: {3}'\n",
    "      .format(m0_AIC, mf_AIC, mg_AIC, mfg_AIC))\n",
    "\n",
    "print('\\nChi2 and reduced chi2 do go down as we go to more complex models, but are they really better?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor approximated with the BIC:\n",
      "\tB_00: 1.0 \tB_0f: 6.2265535363e-07 \tB_0g: 1.05180794321e-07 \tB_0fg: 8.96397635566e-14\n"
     ]
    }
   ],
   "source": [
    "# Bayes factor from BIC\n",
    "b_00_bic = get_bayes_factor(m0_BIC, m0_BIC)\n",
    "b_0f_bic = get_bayes_factor(m0_BIC, mf_BIC)\n",
    "b_0g_bic = get_bayes_factor(m0_BIC, mg_BIC)\n",
    "b_0fg_bic = get_bayes_factor(m0_BIC, mfg_BIC)\n",
    "\n",
    "print('Bayes factor approximated with the BIC:\\n\\tB_00: {0} \\tB_0f: {1} \\tB_0g: {2} \\tB_0fg: {3}'\n",
    "      .format(b_00_bic, b_0f_bic, b_0g_bic, b_0fg_bic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor approximated with the AIC:\n",
      "\tB_00: 1.0 \tB_0f: 3.34276316885e-09 \tB_0g: 5.64669496982e-10 \tB_0fg: 2.58354759108e-18\n"
     ]
    }
   ],
   "source": [
    "# Bayes factor from AIC\n",
    "b_00_aic = get_bayes_factor(m0_AIC, m0_AIC)\n",
    "b_0f_aic = get_bayes_factor(m0_AIC, mf_AIC)\n",
    "b_0g_aic = get_bayes_factor(m0_AIC, mg_AIC)\n",
    "b_0fg_aic = get_bayes_factor(m0_AIC, mfg_AIC)\n",
    "\n",
    "print('Bayes factor approximated with the AIC:\\n\\tB_00: {0} \\tB_0f: {1} \\tB_0g: {2} \\tB_0fg: {3}'\n",
    "      .format(b_00_aic, b_0f_aic, b_0g_aic, b_0fg_aic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# leave p out def\n",
    "def select_training_validation_sets(data, p):\n",
    "    \"\"\"select the training set and the validation set with leave p-out method\n",
    "    Arguments:\n",
    "        data {np.ndarray} -- of full dataset (assuming 2d for now)\n",
    "        p {int} -- number of datapoints to leave out\n",
    "    Return:\n",
    "        t_data {np.ndarray} -- of training set\n",
    "        v_data {np.ndarray} -- of validation set\n",
    "    \"\"\"\n",
    "    num_data_points, num_data_dim = data.shape\n",
    "    assert p < .33 * num_data_points, 'Leaving out too many data points in leave p-out!'\n",
    "    \n",
    "    # placeholder data stacks\n",
    "    t_set_list = []\n",
    "    v_set_list = []\n",
    "\n",
    "    # p choice indices set\n",
    "    p_set = set(np.random.choice(range(num_data_points), p, replace=False))\n",
    "\n",
    "    # assign data rows to data stacks based on if row is in p choice indices set\n",
    "    for r in range(num_data_points):\n",
    "        row = data[r,:]\n",
    "        if r in p_set:\n",
    "            v_set_list.append(row)\n",
    "        else:\n",
    "            t_set_list.append(row)\n",
    "        \n",
    "    t_data = np.vstack(tuple(t_set_list))\n",
    "    v_data = np.vstack(tuple(v_set_list))\n",
    "    return t_data, v_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_cv_on_all_models(p):\n",
    "    \"\"\"cross validation on m0, mf, mg, mfg\n",
    "    Arguments:\n",
    "        p {int} -- number of points in leave p out\n",
    "    Return:\n",
    "        chi2, BIC, AIC for each model (4 by 3 np array)\n",
    "    \"\"\"\n",
    "\n",
    "    training_set, validation_set = select_training_validation_sets(data, p)\n",
    "\n",
    "    # m0: b c d e\n",
    "    # fit m0fix first with training set and update initial guess\n",
    "    cv_m0fix_best, cv_m0fix_cov = curve_fit(M0fix, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                            p0=initial_guess_m0fix, bounds=param_bounds_m0fix)\n",
    "    cv_qb_sol_m0fix, cv_qc_sol_m0fix, cv_qd_sol_m0fix, cv_qe_sol_m0fix = cv_m0fix_best\n",
    "    cv_initial_guess_m0 = [Kb_sol, Pb_sol, cv_qb_sol_m0fix,\n",
    "                           Kc_sol, Pc_sol, cv_qc_sol_m0fix,\n",
    "                           Kd_sol, Pd_sol, cv_qd_sol_m0fix,\n",
    "                           Ke_sol, Pe_sol, cv_qe_sol_m0fix]\n",
    "    # fit m0 with training set and updated initial guess from the m0fix training set fit\n",
    "    cv_m0_best, cv_m0_cov = curve_fit(M0, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                      p0=cv_initial_guess_m0, bounds=param_bounds_m0)\n",
    "    # Get the chi2 from the validation set\n",
    "    cv_m0_chi2 = chi2_model(validation_set, M0, cv_m0_best)\n",
    "    # Get the loglike\n",
    "    cv_m0_loglike = -0.5*len(validation_set)*np.log(2.0*np.pi) - np.sum(np.log(validation_set[:,2])) - 0.5*cv_m0_chi2\n",
    "\n",
    "\n",
    "    # mf: b c d e + f\n",
    "    # fit mffix first with training set and update initial guess\n",
    "    cv_mffix_best, cv_mffix_cov = curve_fit(Mffix, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                            p0=initial_guess_mffix, bounds=param_bounds_mffix)\n",
    "    cv_qb_sol_mffix, cv_qc_sol_mffix, cv_qd_sol_mffix, cv_qe_sol_mffix, cv_qf_sol_mffix = cv_mffix_best\n",
    "    cv_initial_guess_mf = [Kb_sol, Pb_sol, cv_qb_sol_mffix,\n",
    "                           Kc_sol, Pc_sol, cv_qc_sol_mffix,\n",
    "                           Kd_sol, Pd_sol, cv_qd_sol_mffix,\n",
    "                           Ke_sol, Pe_sol, cv_qe_sol_mffix,\n",
    "                           Kf_sol, Pf_sol, cv_qf_sol_mffix]\n",
    "    # fit mf with training set and updated initial guess from the mffix training set fit\n",
    "    cv_mf_best, cv_mf_cov = curve_fit(Mf, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                      p0=cv_initial_guess_mf, bounds=param_bounds_mf)\n",
    "    # Get the chi2 from the validation set\n",
    "    cv_mf_chi2 = chi2_model(validation_set, Mf, cv_mf_best)\n",
    "    # Get the loglike\n",
    "    cv_mf_loglike = -0.5*len(validation_set)*np.log(2.0*np.pi) - np.sum(np.log(validation_set[:,2])) - 0.5*cv_mf_chi2\n",
    "\n",
    "\n",
    "    # mg: b c d e + g\n",
    "    # fit mgfix first with training set and update initial guess\n",
    "    cv_mgfix_best, cv_mgfix_cov = curve_fit(Mgfix, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                            p0=initial_guess_mgfix, bounds=param_bounds_mgfix)\n",
    "    cv_qb_sol_mgfix, cv_qc_sol_mgfix, cv_qd_sol_mgfix, cv_qe_sol_mgfix, cv_qg_sol_mgfix = cv_mgfix_best\n",
    "    cv_initial_guess_mg = [Kb_sol, Pb_sol, cv_qb_sol_mgfix,\n",
    "                           Kc_sol, Pc_sol, cv_qc_sol_mgfix,\n",
    "                           Kd_sol, Pd_sol, cv_qd_sol_mgfix,\n",
    "                           Ke_sol, Pe_sol, cv_qe_sol_mgfix,\n",
    "                           Kg_sol, Pg_sol, cv_qg_sol_mgfix]\n",
    "    # fit mg with training set and updated initial guess from the mgfix training set fit\n",
    "    cv_mg_best, cv_mg_cov = curve_fit(Mg, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                      p0=cv_initial_guess_mg, bounds=param_bounds_mg)\n",
    "    # Get the chi2 from the validation set\n",
    "    cv_mg_chi2 = chi2_model(validation_set, Mg, cv_mg_best)\n",
    "    # Get the loglike\n",
    "    cv_mg_loglike = -0.5*len(validation_set)*np.log(2.0*np.pi) - np.sum(np.log(validation_set[:,2])) - 0.5*cv_mg_chi2\n",
    "\n",
    "\n",
    "    # mfg: b c d e + f g\n",
    "    # fit mfgfix first with training set and update initial guess\n",
    "    cv_mfgfix_best, cv_mfgfix_cov = curve_fit(Mfgfix, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                              p0=initial_guess_mfgfix, bounds=param_bounds_mfgfix)\n",
    "    cv_qb_sol_mfgfix, cv_qc_sol_mfgfix, cv_qd_sol_mfgfix, cv_qe_sol_mfgfix,\\\n",
    "        cv_qf_sol_mfgfix,cv_qg_sol_mfgfix=cv_mfgfix_best\n",
    "    cv_initial_guess_mfg = [Kb_sol, Pb_sol, cv_qb_sol_mfgfix,\n",
    "                            Kc_sol, Pc_sol, cv_qc_sol_mfgfix,\n",
    "                            Kd_sol, Pd_sol, cv_qd_sol_mfgfix,\n",
    "                            Ke_sol, Pe_sol, cv_qe_sol_mfgfix,\n",
    "                            Kf_sol, Pf_sol, cv_qf_sol_mfgfix,\n",
    "                            Kg_sol, Pg_sol, cv_qg_sol_mfgfix]\n",
    "    # fit mfg with training set and updated initial guess from the mfgfix training set fit\n",
    "    cv_mfg_best, cv_mfg_cov = curve_fit(Mfg, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                        p0=cv_initial_guess_mfg, bounds=param_bounds_mfg)\n",
    "\n",
    "    # Get the chi2 from the validation set\n",
    "    cv_mfg_chi2 = chi2_model(validation_set, Mfg, cv_mfg_best)\n",
    "    # Get the loglike\n",
    "    cv_mfg_loglike = -0.5*len(validation_set)*np.log(2.0*np.pi) - np.sum(np.log(validation_set[:,2])) - 0.5*cv_mfg_chi2\n",
    "\n",
    "\n",
    "    cv_N = len(training_set) # number of points in the training set\n",
    "\n",
    "    # AIC and BIC for the validation runs\n",
    "    cv_m0_AIC = get_AIC(cv_m0_loglike, m0_k)\n",
    "    cv_m0_BIC = get_BIC(cv_m0_loglike, m0_k, cv_N)\n",
    "    cv_mf_AIC = get_AIC(cv_mf_loglike, mf_k)\n",
    "    cv_mf_BIC = get_BIC(cv_mf_loglike, mf_k, cv_N)\n",
    "    cv_mg_AIC = get_AIC(cv_mg_loglike, mg_k)\n",
    "    cv_mg_BIC = get_BIC(cv_mg_loglike, mg_k, cv_N)\n",
    "    cv_mfg_AIC = get_AIC(cv_mfg_loglike, mfg_k)\n",
    "    cv_mfg_BIC = get_BIC(cv_mfg_loglike, mfg_k, cv_N)\n",
    "    \n",
    "    # formatting return\n",
    "    r_m0 = np.array([cv_m0_chi2, cv_m0_BIC, cv_m0_AIC])\n",
    "    r_mf = np.array([cv_mf_chi2, cv_mf_BIC, cv_mf_AIC])\n",
    "    r_mg = np.array([cv_mg_chi2, cv_mg_BIC, cv_mg_AIC])\n",
    "    r_mfg = np.array([cv_mfg_chi2, cv_mfg_BIC, cv_mfg_AIC])\n",
    "    return np.vstack((r_m0, r_mf, r_mg, r_mfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV many many times\n",
    "cv_runs = 1000\n",
    "# roughly 20% of our dataset\n",
    "p = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CV results\n",
    "cv_m0_stack_list = []\n",
    "cv_mf_stack_list = []\n",
    "cv_mg_stack_list = []\n",
    "cv_mfg_stack_list = []\n",
    "\n",
    "for i in range(cv_runs):\n",
    "    cv_results = do_cv_on_all_models(p)\n",
    "    cv_m0_stack_list.append(cv_results[0])\n",
    "    cv_mf_stack_list.append(cv_results[1])\n",
    "    cv_mg_stack_list.append(cv_results[2])\n",
    "    cv_mfg_stack_list.append(cv_results[3])\n",
    "\n",
    "cv_m0_stack = np.vstack((cv_m0_stack_list))\n",
    "cv_mf_stack = np.vstack((cv_mf_stack_list))\n",
    "cv_mg_stack = np.vstack((cv_mg_stack_list))\n",
    "cv_mfg_stack = np.vstack((cv_mfg_stack_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, over 1000 iterations of cross validation with leave p-out (p = 50):\n",
      "M0:\n",
      "\tChi2: 89.5055679639 \tBIC: 307.114269084 \tAIC: 89.5055679639\n",
      "Mf:\n",
      "\tChi2: 80.5815135805 \tBIC: 313.947034985 \tAIC: 80.5815135805\n",
      "Mg:\n",
      "\tChi2: 80.1307611087 \tBIC: 313.496282513 \tAIC: 80.1307611087\n",
      "Mfg:\n",
      "\tChi2: 71.2653877773 \tBIC: 320.387729465 \tAIC: 71.2653877773\n"
     ]
    }
   ],
   "source": [
    "print('On average, over {0} iterations of cross validation with leave p-out (p = {1}):'.format(cv_runs, p))\n",
    "print('M0:\\n\\tChi2: {0} \\tBIC: {1} \\tAIC: {0}'.format(*tuple(np.mean(cv_m0_stack, 0))))\n",
    "print('Mf:\\n\\tChi2: {0} \\tBIC: {1} \\tAIC: {0}'.format(*tuple(np.mean(cv_mf_stack, 0))))\n",
    "print('Mg:\\n\\tChi2: {0} \\tBIC: {1} \\tAIC: {0}'.format(*tuple(np.mean(cv_mg_stack, 0))))\n",
    "print('Mfg:\\n\\tChi2: {0} \\tBIC: {1} \\tAIC: {0}'.format(*tuple(np.mean(cv_mfg_stack, 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor approximated with the BIC (average CV):\n",
      "\tB_00: 1.0 \tB_0f: 30.4590436591 \tB_0g: 24.312891266 \tB_0fg: 762.597363997\n"
     ]
    }
   ],
   "source": [
    "# Bayes factor from cross validation BIC\n",
    "_, cv_m0_avg_BIC, cv_m0_avg_AIC = np.mean(cv_m0_stack, 0)\n",
    "_, cv_mf_avg_BIC, cv_mf_avg_AIC = np.mean(cv_mf_stack, 0)\n",
    "_, cv_mg_avg_BIC, cv_mg_avg_AIC = np.mean(cv_mg_stack, 0)\n",
    "_, cv_mfg_avg_BIC, cv_mfg_avg_AIC = np.mean(cv_mfg_stack, 0)\n",
    "\n",
    "b_00_cv_avg_bic = get_bayes_factor(cv_m0_avg_BIC, cv_m0_avg_BIC)\n",
    "b_0f_cv_avg_bic = get_bayes_factor(cv_m0_avg_BIC, cv_mf_avg_BIC)\n",
    "b_0g_cv_avg_bic = get_bayes_factor(cv_m0_avg_BIC, cv_mg_avg_BIC)\n",
    "b_0fg_cv_avg_bic = get_bayes_factor(cv_m0_avg_BIC, cv_mfg_avg_BIC)\n",
    "\n",
    "print('Bayes factor approximated with the BIC (average CV):\\n\\tB_00: {0} \\tB_0f: {1} \\tB_0g: {2} \\tB_0fg: {3}'\n",
    "      .format(b_00_cv_avg_bic, b_0f_cv_avg_bic, b_0g_cv_avg_bic, b_0fg_cv_avg_bic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor approximated with the AIC (average CV):\n",
      "\tB_00: 1.0 \tB_0f: 0.231765964145 \tB_0g: 0.184999264865 \tB_0fg: 0.0441531903329\n"
     ]
    }
   ],
   "source": [
    "# Bayes factor from cross validation AIC\n",
    "b_00_cv_avg_aic = get_bayes_factor(cv_m0_avg_AIC, cv_m0_avg_AIC)\n",
    "b_0f_cv_avg_aic = get_bayes_factor(cv_m0_avg_AIC, cv_mf_avg_AIC)\n",
    "b_0g_cv_avg_aic = get_bayes_factor(cv_m0_avg_AIC, cv_mg_avg_AIC)\n",
    "b_0fg_cv_avg_aic = get_bayes_factor(cv_m0_avg_AIC, cv_mfg_avg_AIC)\n",
    "\n",
    "print('Bayes factor approximated with the AIC (average CV):\\n\\tB_00: {0} \\tB_0f: {1} \\tB_0g: {2} \\tB_0fg: {3}'\n",
    "      .format(b_00_cv_avg_aic, b_0f_cv_avg_aic, b_0g_cv_avg_aic, b_0fg_cv_avg_aic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# looking at individual CV runs\n",
    "cv_results_chi2_best = np.zeros((cv_runs, 4), dtype=int)\n",
    "cv_results_bic_best = np.zeros((cv_runs, 4), dtype=int)\n",
    "cv_results_aic_best = np.zeros((cv_runs, 4), dtype=int)\n",
    "\n",
    "for i in range(cv_runs):\n",
    "    # checking which model had the \"best\" performance on the validation set\n",
    "    min_chi2_ind = np.argmin([cv_m0_stack[i][0], cv_mf_stack[i][0], cv_mg_stack[i][0], cv_mfg_stack[i][0]])\n",
    "    min_bic_ind = np.argmin([cv_m0_stack[i][1], cv_mf_stack[i][1], cv_mg_stack[i][1], cv_mfg_stack[i][1]])\n",
    "    min_aic_ind = np.argmin([cv_m0_stack[i][2], cv_mf_stack[i][2], cv_mg_stack[i][2], cv_mfg_stack[i][2]])\n",
    "    cv_results_chi2_best[i][min_chi2_ind] = 1\n",
    "    cv_results_bic_best[i][min_bic_ind] = 1\n",
    "    cv_results_aic_best[i][min_aic_ind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_results_chi2_best_sum = np.sum(cv_results_chi2_best, 0)\n",
    "cv_results_bic_best_sum = np.sum(cv_results_bic_best, 0)\n",
    "cv_results_aic_best_sum = np.sum(cv_results_aic_best, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAADkCAYAAAAxfOZYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f3469d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure(figsize=(9,3))\n",
    "ax1 = fig1.add_subplot(131)\n",
    "ax2 = fig1.add_subplot(132)\n",
    "ax3 = fig1.add_subplot(133)\n",
    "\n",
    "model_names = ('M0', 'Mf', 'Mg', 'Mfg')\n",
    "x = range(4)\n",
    "\n",
    "# bar graph of rate of the model being the best model\n",
    "rects1 = ax1.bar(x, cv_results_chi2_best_sum, color='gray', align='center', tick_label=model_names)\n",
    "rects2 = ax2.bar(x, cv_results_bic_best_sum, color='gray', align='center', tick_label=model_names)\n",
    "rects3 = ax3.bar(x, cv_results_aic_best_sum, color='gray', align='center', tick_label=model_names)\n",
    "\n",
    "ax1.tick_params(axis='x', which='both', length=0)\n",
    "ax2.tick_params(axis='x', which='both', length=0)\n",
    "ax3.tick_params(axis='x', which='both', length=0)\n",
    "\n",
    "def autolabel(rects, axs):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    adapted from http://matplotlib.org/examples/api/barchart_demo.html\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        axs.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                 '%d' % int(height), ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1, ax1)\n",
    "autolabel(rects2, ax2)\n",
    "autolabel(rects3, ax3)\n",
    "\n",
    "ax1.set_ylim([0,900])\n",
    "ax2.set_ylim([0,800])\n",
    "ax3.set_ylim([0,600])\n",
    "\n",
    "ax1.set_xlabel('lowest chi2')\n",
    "ax2.set_xlabel('lowest BIC')\n",
    "ax3.set_xlabel('lowest AIC')\n",
    "fig1.suptitle('After 1000 Cross Validation Trials')\n",
    "\n",
    "fig1.show()\n",
    "fig1.savefig('../figures/cv_res.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

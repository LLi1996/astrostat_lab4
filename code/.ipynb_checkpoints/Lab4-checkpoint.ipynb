{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astrostat Lab4: model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryli/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119  HARPS points;  122  HIRES points\n",
      "Initial run of M0fix: chi2 = 395.796125725, 241 points\n",
      "Real M0 run: chi2 = 390.391712065, loglike = -567.778155919\n"
     ]
    }
   ],
   "source": [
    "# run the original notebook for M0fix and M0\n",
    "%run 'fit.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import erf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define BIC, AIC, reduced chi2, bayes factor functions\n",
    "\n",
    "def get_BIC(loglike, k, N):\n",
    "    \"\"\"calculates the BIC\n",
    "    Arguments:\n",
    "        loglike {float} -- log likelihood\n",
    "        k {int} -- number of parameters\n",
    "        N {int} -- number of data points\n",
    "    Return:\n",
    "        BIC {float} -- Bayesian Information Criterion\n",
    "    \"\"\"\n",
    "    BIC = k * np.log(N) - 2 * loglike\n",
    "    return BIC\n",
    "\n",
    "\n",
    "def get_AIC(loglike, k):\n",
    "    \"\"\"calculates the AIC\n",
    "    Arguments:\n",
    "        loglike {float} -- log likelihood\n",
    "        k {int} -- number of parameters\n",
    "    Return:\n",
    "        AIC {float} -- Akaike Information Criterion\n",
    "    \"\"\"\n",
    "    AIC = 2 * k - 2 * loglike\n",
    "    return AIC\n",
    "\n",
    "def get_reduced_chi2(chi2, k, N):\n",
    "    \"\"\"calculates the reduced chi2\n",
    "    Arguments:\n",
    "        chi2 {float} -- log likelihood\n",
    "        k {int} -- number of parameters\n",
    "        N {int} -- number of data points\n",
    "    Return:\n",
    "        reduced_chi2 {float}\n",
    "    \"\"\"\n",
    "    reduced_chi2 = chi2 / (N - k)\n",
    "    return reduced_chi2\n",
    "\n",
    "def get_bayes_factor(IC1, IC2):\n",
    "    \"\"\"calculates the bayes factor\n",
    "    Arguments:\n",
    "        IC1 {float} -- could be BIC or AIC for the first model\n",
    "        IC2 {float} -- could be BIC or AIC for the second model\n",
    "    return:\n",
    "        bayes_factor {float} -- is > 1 if IC1 < IC2\n",
    "    \"\"\"\n",
    "    bayes_factor = np.e ** (-.5 * (IC1 - IC2))\n",
    "    return bayes_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chi2 from model def\n",
    "def chi2_model(data, model, best_fit_params):\n",
    "    \"\"\"calculates chi2 based on model and best fit\n",
    "    Arguments:\n",
    "        data {np.ndarray} -- real data\n",
    "        model {function} -- model\n",
    "        best_fit_params {list} -- of best fit values, must match model input params\n",
    "    \"\"\"\n",
    "    chi2 = 0.0\n",
    "    for i in range(len(data)):\n",
    "        m_sol = model(data[i, 0], *best_fit_params)\n",
    "        chi2 = chi2 + ((data[i, 1] - m_sol) / data[i,2])**2\n",
    "    return chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M0fix & M0 (coded up in fix.ipynb): planets b c d e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# easy def for later use in CV\n",
    "param_bounds_m0fix = ([-2.*np.pi]*4, [2.*np.pi]*4)\n",
    "initial_guess_m0fix = [np.random.uniform(-np.pi,np.pi)]*4\n",
    "\n",
    "param_bounds_m0 = ([0.0,  Pb_sol-3.0*Pb_del, -2.0*np.pi,\n",
    "                    0.0,  Pc_sol-3.0*Pc_del, -2.0*np.pi,\n",
    "                    0.0,  Pd_sol-3.0*Pd_del, -2.0*np.pi,\n",
    "                    0.0,  Pe_sol-3.0*Pe_del, -2.0*np.pi],\n",
    "                   [20.0, Pb_sol+3.0*Pb_del,  2.0*np.pi,\n",
    "                    20.0, Pc_sol+3.0*Pc_del,  2.0*np.pi,\n",
    "                    20.0, Pd_sol+3.0*Pd_del,  2.0*np.pi,\n",
    "                    20.0, Pe_sol+3.0*Pe_del,  2.0*np.pi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m0_N = 119 + 122 # HARPS and HIRES datapoints\n",
    "m0_k = 12 # degrees of freedom\n",
    "m0_chi2 = 390.531407575 # from fit.ipynb run\n",
    "m0_loglike = -567.848003674 # from fit.ipynb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m0_AIC = get_AIC(m0_loglike, m0_k)\n",
    "m0_BIC = get_BIC(m0_loglike, m0_k, m0_N)\n",
    "m0_rchi2 = get_reduced_chi2(m0_chi2, m0_k, m0_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mffix & Mf: planets b c d e + f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 planet + f model with K & P fixed to Vogt+ reported values\n",
    "def Mffix(t, qb, qc, qd, qe, qf):\n",
    "    return Kb_sol*np.sin(2.0*np.pi*t/Pb_sol+qb)\\\n",
    "           + Kc_sol*np.sin(2.0*np.pi*t/Pc_sol+qc)\\\n",
    "           + Kd_sol*np.sin(2.0*np.pi*t/Pd_sol+qd)\\\n",
    "           + Ke_sol*np.sin(2.0*np.pi*t/Pe_sol+qe)\\\n",
    "           + Kf_sol*np.sin(2.0*np.pi*t/Pf_sol+qf)\n",
    "\n",
    "# 4 planet + f full model\n",
    "def Mf(t, Kb, Pb, qb, Kc, Pc, qc, Kd, Pd, qd, Ke, Pe, qe, Kf, Pf, qf):\n",
    "    return Kb*np.sin(2.0*np.pi*t/Pb+qb)\\\n",
    "           + Kc*np.sin(2.0*np.pi*t/Pc+qc)\\\n",
    "           + Kd*np.sin(2.0*np.pi*t/Pd+qd)\\\n",
    "           + Ke*np.sin(2.0*np.pi*t/Pe+qe)\\\n",
    "           + Kf*np.sin(2.0*np.pi*t/Pf+qf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mffix\n",
    "param_bounds_mffix = ([-2.*np.pi]*5, [2.*np.pi]*5)\n",
    "\n",
    "initial_guess_mffix = [np.random.uniform(-np.pi,np.pi)]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mffix: chi2 = 349.597443429, 241 points\n"
     ]
    }
   ],
   "source": [
    "# fit Mffix and get best fitting parameters and chi2\n",
    "Mffix_best, Mffix_cov = curve_fit(Mffix, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                                  p0=initial_guess_mffix, bounds=param_bounds_mffix)\n",
    "\n",
    "# Get the chi2\n",
    "mffix_chi2 = chi2_model(data, Mffix, Mffix_best)\n",
    "\n",
    "# Print output\n",
    "print('Mffix: chi2 = {0}, {1} points'.format(mffix_chi2,len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting phase solutions as initial guesses for Mf\n",
    "qb_sol_mffix, qc_sol_mffix, qd_sol_mffix, qe_sol_mffix, qf_sol_mffix = Mffix_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mf, first four bounds same as m0\n",
    "param_bounds_mf = (param_bounds_m0[0] + [0.0,  Pf_sol-3.0*Pf_del, -2.0*np.pi],\n",
    "                   param_bounds_m0[1] + [20.0, Pf_sol+3.0*Pf_del,  2.0*np.pi])\n",
    "\n",
    "# mffix results as inputs\n",
    "initial_guess_mf = [Kb_sol, Pb_sol, qb_sol_mffix,\n",
    "                    Kc_sol, Pc_sol, qc_sol_mffix,\n",
    "                    Kd_sol, Pd_sol, qd_sol_mffix,\n",
    "                    Ke_sol, Pe_sol, qe_sol_mffix,\n",
    "                    Kf_sol, Pf_sol, qf_sol_mffix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mf run: chi2 = 345.498471424, loglike = -545.331535598\n"
     ]
    }
   ],
   "source": [
    "# fit Mf and get best fitting parameters and chi2 and loglike\n",
    "Mf_best, Mf_cov = curve_fit(Mf, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                            p0=initial_guess_mf, bounds=param_bounds_mf)\n",
    "\n",
    "# Get the chi2\n",
    "mf_chi2 = chi2_model(data, Mf, Mf_best)\n",
    "\n",
    "# Get the loglike\n",
    "mf_loglike = -0.5*len(data)*np.log(2.0*np.pi) - np.sum(np.log(data[:,2])) - 0.5*mf_chi2\n",
    "\n",
    "# Print output\n",
    "print('Mf run: chi2 = {0}, loglike = {1}'.format(mf_chi2,mf_loglike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AIC, BIC, reduced chi2 for Mf\n",
    "mf_N = m0_N # same number of datapoints\n",
    "mf_k = 15 # degrees of freedom\n",
    "\n",
    "mf_AIC = get_AIC(mf_loglike, mf_k)\n",
    "mf_BIC = get_BIC(mf_loglike, mf_k, mf_N)\n",
    "mf_rchi2 = get_reduced_chi2(mf_chi2, mf_k, mf_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mgfix & Mg: planets b c d e + g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 planet + g model with K & P fixed to Vogt+ reported values\n",
    "def Mgfix(t, qb, qc, qd, qe, qg):\n",
    "    return Kb_sol*np.sin(2.0*np.pi*t/Pb_sol+qb)\\\n",
    "           + Kc_sol*np.sin(2.0*np.pi*t/Pc_sol+qc)\\\n",
    "           + Kd_sol*np.sin(2.0*np.pi*t/Pd_sol+qd)\\\n",
    "           + Ke_sol*np.sin(2.0*np.pi*t/Pe_sol+qe)\\\n",
    "           + Kg_sol*np.sin(2.0*np.pi*t/Pg_sol+qg)\n",
    "\n",
    "# 4 planet + g full model\n",
    "# in reality this is the same model as Mf (a 4 sinusoid with no fixed parameters)\n",
    "def Mg(t, Kb, Pb, qb, Kc, Pc, qc, Kd, Pd, qd, Ke, Pe, qe, Kg, Pg, qg):\n",
    "    return Mf(t, Kb, Pb, qb, Kc, Pc, qc, Kd, Pd, qd, Ke, Pe, qe, Kg, Pg, qg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mffix\n",
    "param_bounds_mgfix = ([-2.*np.pi]*5, [2.*np.pi]*5)\n",
    "\n",
    "initial_guess_mgfix = [np.random.uniform(-np.pi,np.pi)]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mgfix: chi2 = 347.861935825, 241 points\n"
     ]
    }
   ],
   "source": [
    "# fit Mffix and get best fitting parameters and chi2\n",
    "Mgfix_best, Mgfix_cov = curve_fit(Mgfix, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                                  p0=initial_guess_mgfix, bounds=param_bounds_mgfix)\n",
    "\n",
    "# Get the chi2\n",
    "mgfix_chi2 = chi2_model(data, Mgfix, Mgfix_best)\n",
    "\n",
    "# Print output\n",
    "print('Mgfix: chi2 = {0}, {1} points'.format(mgfix_chi2,len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting phase solutions as initial guesses for Mg\n",
    "qb_sol_mgfix, qc_sol_mgfix, qd_sol_mgfix, qe_sol_mgfix, qg_sol_mgfix = Mgfix_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mg\n",
    "# the first 4 bounds are the same as for M0\n",
    "param_bounds_mg = (param_bounds_m0[0] + [0.0, Pg_sol-3.0*Pg_del, -2.0*np.pi],\n",
    "                   param_bounds_m0[1] + [20.0, Pg_sol+3.0*Pg_del,  2.0*np.pi])\n",
    "\n",
    "# mgfix results as inputs\n",
    "initial_guess_mg = [Kb_sol, Pb_sol, qb_sol_mgfix,\n",
    "                    Kc_sol, Pc_sol, qc_sol_mgfix,\n",
    "                    Kd_sol, Pd_sol, qd_sol_mgfix,\n",
    "                    Ke_sol, Pe_sol, qe_sol_mgfix,\n",
    "                    Kg_sol, Pg_sol, qg_sol_mgfix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mg run: chi2 = 341.941846542, loglike = -543.553223157\n"
     ]
    }
   ],
   "source": [
    "# fit Mg and get best fitting parameters and chi2 and loglike\n",
    "Mg_best, Mg_cov = curve_fit(Mg, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                            p0=initial_guess_mg, bounds=param_bounds_mg)\n",
    "\n",
    "# Get the chi2\n",
    "mg_chi2 = chi2_model(data, Mg, Mg_best)\n",
    "\n",
    "# Get the loglike\n",
    "mg_loglike = -0.5*len(data)*np.log(2.0*np.pi) - np.sum(np.log(data[:,2])) - 0.5*mg_chi2\n",
    "\n",
    "# Print output\n",
    "print('Mg run: chi2 = {0}, loglike = {1}'.format(mg_chi2, mg_loglike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AIC, BIC, reduced chi2 for Mg\n",
    "mg_N = m0_N # same number of datapoints\n",
    "mg_k = 15 # degrees of freedom\n",
    "\n",
    "mg_AIC = get_AIC(mg_loglike, mg_k)\n",
    "mg_BIC = get_BIC(mg_loglike, mg_k, mg_N)\n",
    "mg_rchi2 = get_reduced_chi2(mg_chi2, mg_k, mg_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mfgfix & Mfg: planets b c d e + f&g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 planet + f + g model with K & P fixed to Vogt+ reported values\n",
    "def Mfgfix(t, qb, qc, qd, qe, qf, qg):\n",
    "    return Kb_sol*np.sin(2.0*np.pi*t/Pb_sol+qb)\\\n",
    "           + Kc_sol*np.sin(2.0*np.pi*t/Pc_sol+qc)\\\n",
    "           + Kd_sol*np.sin(2.0*np.pi*t/Pd_sol+qd)\\\n",
    "           + Ke_sol*np.sin(2.0*np.pi*t/Pe_sol+qe)\\\n",
    "           + Kf_sol*np.sin(2.0*np.pi*t/Pf_sol+qf)\\\n",
    "           + Kg_sol*np.sin(2.0*np.pi*t/Pg_sol+qg)\n",
    "\n",
    "# 4 planet + f + g full model\n",
    "def Mfg(t, Kb, Pb, qb, Kc, Pc, qc, Kd, Pd, qd, Ke, Pe, qe, Kf, Pf, qf, Kg, Pg, qg):\n",
    "    return Kb*np.sin(2.0*np.pi*t/Pb+qb)\\\n",
    "           + Kc*np.sin(2.0*np.pi*t/Pc+qc)\\\n",
    "           + Kd*np.sin(2.0*np.pi*t/Pd+qd)\\\n",
    "           + Ke*np.sin(2.0*np.pi*t/Pe+qe)\\\n",
    "           + Kf*np.sin(2.0*np.pi*t/Pf+qf)\\\n",
    "           + Kg*np.sin(2.0*np.pi*t/Pg+qg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mfgfix\n",
    "param_bounds_mfgfix = ([-2.*np.pi]*6, [2.*np.pi]*6)\n",
    "\n",
    "initial_guess_mfgfix = [np.random.uniform(-np.pi,np.pi)]*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mfgfix: chi2 = 302.861634452, 241 points\n"
     ]
    }
   ],
   "source": [
    "# fit Mfgfix and get best fitting parameters and chi2\n",
    "Mfgfix_best, Mfgfix_cov = curve_fit(Mfgfix, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                                  p0=initial_guess_mfgfix, bounds=param_bounds_mfgfix)\n",
    "\n",
    "# Get the chi2\n",
    "mfgfix_chi2 = chi2_model(data, Mfgfix, Mfgfix_best)\n",
    "\n",
    "# Print output\n",
    "print('Mfgfix: chi2 = {0}, {1} points'.format(mfgfix_chi2,len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting phase solutions as initial guesses for Mfg\n",
    "qb_sol_mfgfix, qc_sol_mfgfix, qd_sol_mfgfix, qe_sol_mfgfix, qf_sol_mfgfix, qg_sol_mfgfix = Mfgfix_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# param bounds and initial guesses for Mfg\n",
    "# the first 5 bounds are the same as for Mf\n",
    "param_bounds_mfg = (param_bounds_mf[0] + [0.0, Pg_sol-3.0*Pg_del, -2.0*np.pi],\n",
    "                   param_bounds_mf[1] + [20.0, Pg_sol+3.0*Pg_del,  2.0*np.pi])\n",
    "\n",
    "# mgfix results as inputs\n",
    "initial_guess_mfg = [Kb_sol, Pb_sol, qb_sol_mfgfix,\n",
    "                    Kc_sol, Pc_sol, qc_sol_mfgfix,\n",
    "                    Kd_sol, Pd_sol, qd_sol_mfgfix,\n",
    "                    Ke_sol, Pe_sol, qe_sol_mfgfix,\n",
    "                    Kf_sol, Pf_sol, qf_sol_mfgfix,\n",
    "                    Kg_sol, Pg_sol, qg_sol_mfgfix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mg run: chi2 = 297.536671208, loglike = -521.35063549\n"
     ]
    }
   ],
   "source": [
    "# fit Mg and get best fitting parameters and chi2 and loglike\n",
    "Mfg_best, Mfg_cov = curve_fit(Mfg, data[:,0], data[:,1], sigma=data[:,2],\n",
    "                              p0=initial_guess_mfg, bounds=param_bounds_mfg)\n",
    "\n",
    "# Get the chi2\n",
    "mfg_chi2 = chi2_model(data, Mfg, Mfg_best)\n",
    "\n",
    "# Get the loglike\n",
    "mfg_loglike = -0.5*len(data)*np.log(2.0*np.pi) - np.sum(np.log(data[:,2])) - 0.5*mfg_chi2\n",
    "\n",
    "# Print output\n",
    "print('Mg run: chi2 = {0}, loglike = {1}'.format(mfg_chi2, mfg_loglike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AIC, BIC, reduced chi2 for Mfg\n",
    "mfg_N = m0_N # same number of datapoints\n",
    "mfg_k = 18 # degrees of freedom\n",
    "\n",
    "mfg_AIC = get_AIC(mfg_loglike, mfg_k)\n",
    "mfg_BIC = get_BIC(mfg_loglike, mfg_k, mfg_N)\n",
    "mfg_rchi2 = get_reduced_chi2(mfg_chi2, mfg_k, mfg_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Simple model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2:\n",
      "\tM0: 390.531407575 \tMf: 345.498471424 \tMg: 341.941846542 \tMfg: 297.536671208\n",
      "Reduced chi2:\n",
      "\tM0: 1.70537732566 \tMf: 1.52875429834 \tMg: 1.5130170201 \tMfg: 1.33424516237\n",
      "BIC:\n",
      "\tM0: 1201.51357055 \tMf: 1172.9350252 \tMg: 1169.37840032 \tMfg: 1141.42761578\n",
      "AIC:\n",
      "\tM0: 1159.69600735 \tMf: 1120.6630712 \tMg: 1117.10644631 \tMfg: 1078.70127098\n",
      "\n",
      "Chi2 and reduced chi2 do go down as we go to more complex models, but are they really better?\n"
     ]
    }
   ],
   "source": [
    "# looking at results\n",
    "print('Chi2:\\n\\tM0: {0} \\tMf: {1} \\tMg: {2} \\tMfg: {3}'\n",
    "      .format(m0_chi2, mf_chi2, mg_chi2, mfg_chi2))\n",
    "print('Reduced chi2:\\n\\tM0: {0} \\tMf: {1} \\tMg: {2} \\tMfg: {3}'\n",
    "      .format(m0_rchi2, mf_rchi2, mg_rchi2, mfg_rchi2))\n",
    "print('BIC:\\n\\tM0: {0} \\tMf: {1} \\tMg: {2} \\tMfg: {3}'\n",
    "      .format(m0_BIC, mf_BIC, mg_BIC, mfg_BIC))\n",
    "print('AIC:\\n\\tM0: {0} \\tMf: {1} \\tMg: {2} \\tMfg: {3}'\n",
    "      .format(m0_AIC, mf_AIC, mg_AIC, mfg_AIC))\n",
    "\n",
    "print('\\nChi2 and reduced chi2 do go down as we go to more complex models, but are they really better?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor approximated with the BIC:\n",
      "\tB_00: 1.0 \tB_0f: 6.2265535363e-07 \tB_0g: 1.05180794321e-07 \tB_0fg: 8.96397635566e-14\n"
     ]
    }
   ],
   "source": [
    "# Bayes factor from BIC\n",
    "b_00_bic = get_bayes_factor(m0_BIC, m0_BIC)\n",
    "b_0f_bic = get_bayes_factor(m0_BIC, mf_BIC)\n",
    "b_0g_bic = get_bayes_factor(m0_BIC, mg_BIC)\n",
    "b_0fg_bic = get_bayes_factor(m0_BIC, mfg_BIC)\n",
    "\n",
    "print('Bayes factor approximated with the BIC:\\n\\tB_00: {0} \\tB_0f: {1} \\tB_0g: {2} \\tB_0fg: {3}'\n",
    "      .format(b_00_bic, b_0f_bic, b_0g_bic, b_0fg_bic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor approximated with the AIC:\n",
      "\tB_00: 1.0 \tB_0f: 3.34276316885e-09 \tB_0g: 5.64669496982e-10 \tB_0fg: 2.58354759108e-18\n"
     ]
    }
   ],
   "source": [
    "# Bayes factor from AIC\n",
    "b_00_aic = get_bayes_factor(m0_AIC, m0_AIC)\n",
    "b_0f_aic = get_bayes_factor(m0_AIC, mf_AIC)\n",
    "b_0g_aic = get_bayes_factor(m0_AIC, mg_AIC)\n",
    "b_0fg_aic = get_bayes_factor(m0_AIC, mfg_AIC)\n",
    "\n",
    "print('Bayes factor approximated with the AIC:\\n\\tB_00: {0} \\tB_0f: {1} \\tB_0g: {2} \\tB_0fg: {3}'\n",
    "      .format(b_00_aic, b_0f_aic, b_0g_aic, b_0fg_aic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in terms of sigmas...\n",
    "# from BIC\n",
    "p_b_00_bic = 1. / (1 + b_00_bic)\n",
    "p_b_0f_bic = 1. / (1 + b_0f_bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47950012218695348"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - erf(p_b_00_bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15729940435240219"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - erf(p_b_0f_bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99730020393724572"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erf(3*0.7071067812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "O12 = 4 means that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# leave p out def\n",
    "def select_training_validation_sets(data, p):\n",
    "    \"\"\"select the training set and the validation set with leave p-out method\n",
    "    Arguments:\n",
    "        data {np.ndarray} -- of full dataset (assuming 2d for now)\n",
    "        p {int} -- number of datapoints to leave out\n",
    "    Return:\n",
    "        t_data {np.ndarray} -- of training set\n",
    "        v_data {np.ndarray} -- of validation set\n",
    "    \"\"\"\n",
    "    num_data_points, num_data_dim = data.shape\n",
    "    assert p < .33 * num_data_points, 'Leaving out too many data points in leave p-out!'\n",
    "    \n",
    "    # placeholder data stacks\n",
    "    t_set_list = []\n",
    "    v_set_list = []\n",
    "\n",
    "    # p choice indices set\n",
    "    p_set = set(np.random.choice(range(num_data_points), p, replace=False))\n",
    "\n",
    "    # assign data rows to data stacks based on if row is in p choice indices set\n",
    "    for r in range(num_data_points):\n",
    "        row = data[r,:]\n",
    "        if r in p_set:\n",
    "            v_set_list.append(row)\n",
    "        else:\n",
    "            t_set_list.append(row)\n",
    "        \n",
    "    t_data = np.vstack(tuple(t_set_list))\n",
    "    v_data = np.vstack(tuple(v_set_list))\n",
    "    return t_data, v_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_cv_on_all_models(p):\n",
    "    \"\"\"cross validation on m0, mf, mg, mfg\n",
    "    Arguments:\n",
    "        p {int} -- number of points in leave p out\n",
    "    Return:\n",
    "        chi2, BIC, AIC for each model (4 by 3 np array)\n",
    "    \"\"\"\n",
    "\n",
    "    training_set, validation_set = select_training_validation_sets(data, p)\n",
    "\n",
    "    # m0: b c d e\n",
    "    # fit m0fix first with training set and update initial guess\n",
    "    cv_m0fix_best, cv_m0fix_cov = curve_fit(M0fix, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                            p0=initial_guess_m0fix, bounds=param_bounds_m0fix)\n",
    "    cv_qb_sol_m0fix, cv_qc_sol_m0fix, cv_qd_sol_m0fix, cv_qe_sol_m0fix = cv_m0fix_best\n",
    "    cv_initial_guess_m0 = [Kb_sol, Pb_sol, cv_qb_sol_m0fix,\n",
    "                           Kc_sol, Pc_sol, cv_qc_sol_m0fix,\n",
    "                           Kd_sol, Pd_sol, cv_qd_sol_m0fix,\n",
    "                           Ke_sol, Pe_sol, cv_qe_sol_m0fix]\n",
    "    # fit m0 with training set and updated initial guess from the m0fix training set fit\n",
    "    cv_m0_best, cv_m0_cov = curve_fit(M0, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                      p0=cv_initial_guess_m0, bounds=param_bounds_m0)\n",
    "    # Get the chi2 from the validation set\n",
    "    cv_m0_chi2 = chi2_model(validation_set, M0, cv_m0_best)\n",
    "    # Get the loglike\n",
    "    cv_m0_loglike = -0.5*len(data)*np.log(2.0*np.pi) - np.sum(np.log(data[:,2])) - 0.5*cv_m0_chi2\n",
    "\n",
    "\n",
    "    # mf: b c d e + f\n",
    "    # fit mffix first with training set and update initial guess\n",
    "    cv_mffix_best, cv_mffix_cov = curve_fit(Mffix, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                            p0=initial_guess_mffix, bounds=param_bounds_mffix)\n",
    "    cv_qb_sol_mffix, cv_qc_sol_mffix, cv_qd_sol_mffix, cv_qe_sol_mffix, cv_qf_sol_mffix = cv_mffix_best\n",
    "    cv_initial_guess_mf = [Kb_sol, Pb_sol, cv_qb_sol_mffix,\n",
    "                           Kc_sol, Pc_sol, cv_qc_sol_mffix,\n",
    "                           Kd_sol, Pd_sol, cv_qd_sol_mffix,\n",
    "                           Ke_sol, Pe_sol, cv_qe_sol_mffix,\n",
    "                           Kf_sol, Pf_sol, cv_qf_sol_mffix]\n",
    "    # fit mf with training set and updated initial guess from the mffix training set fit\n",
    "    cv_mf_best, cv_mf_cov = curve_fit(Mf, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                      p0=cv_initial_guess_mf, bounds=param_bounds_mf)\n",
    "    # Get the chi2 from the validation set\n",
    "    cv_mf_chi2 = chi2_model(validation_set, Mf, cv_mf_best)\n",
    "    # Get the loglike\n",
    "    cv_mf_loglike = -0.5*len(data)*np.log(2.0*np.pi) - np.sum(np.log(data[:,2])) - 0.5*cv_mf_chi2\n",
    "\n",
    "\n",
    "    # mg: b c d e + g\n",
    "    # fit mgfix first with training set and update initial guess\n",
    "    cv_mgfix_best, cv_mgfix_cov = curve_fit(Mgfix, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                            p0=initial_guess_mgfix, bounds=param_bounds_mgfix)\n",
    "    cv_qb_sol_mgfix, cv_qc_sol_mgfix, cv_qd_sol_mgfix, cv_qe_sol_mgfix, cv_qg_sol_mgfix = cv_mgfix_best\n",
    "    cv_initial_guess_mg = [Kb_sol, Pb_sol, cv_qb_sol_mgfix,\n",
    "                           Kc_sol, Pc_sol, cv_qc_sol_mgfix,\n",
    "                           Kd_sol, Pd_sol, cv_qd_sol_mgfix,\n",
    "                           Ke_sol, Pe_sol, cv_qe_sol_mgfix,\n",
    "                           Kg_sol, Pg_sol, cv_qg_sol_mgfix]\n",
    "    # fit mg with training set and updated initial guess from the mgfix training set fit\n",
    "    cv_mg_best, cv_mg_cov = curve_fit(Mg, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                      p0=cv_initial_guess_mg, bounds=param_bounds_mg)\n",
    "    # Get the chi2 from the validation set\n",
    "    cv_mg_chi2 = chi2_model(validation_set, Mg, cv_mg_best)\n",
    "    # Get the loglike\n",
    "    cv_mg_loglike = -0.5*len(data)*np.log(2.0*np.pi) - np.sum(np.log(data[:,2])) - 0.5*cv_mg_chi2\n",
    "\n",
    "\n",
    "    # mfg: b c d e + f g\n",
    "    # fit mfgfix first with training set and update initial guess\n",
    "    cv_mfgfix_best, cv_mfgfix_cov = curve_fit(Mfgfix, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                              p0=initial_guess_mfgfix, bounds=param_bounds_mfgfix)\n",
    "    cv_qb_sol_mfgfix, cv_qc_sol_mfgfix, cv_qd_sol_mfgfix, cv_qe_sol_mfgfix, cv_qf_sol_mfgfix, cv_qg_sol_mfgfix = cv_mfgfix_best\n",
    "    cv_initial_guess_mfg = [Kb_sol, Pb_sol, cv_qb_sol_mfgfix,\n",
    "                            Kc_sol, Pc_sol, cv_qc_sol_mfgfix,\n",
    "                            Kd_sol, Pd_sol, cv_qd_sol_mfgfix,\n",
    "                            Ke_sol, Pe_sol, cv_qe_sol_mfgfix,\n",
    "                            Kf_sol, Pf_sol, cv_qf_sol_mfgfix,\n",
    "                            Kg_sol, Pg_sol, cv_qg_sol_mfgfix]\n",
    "    # fit mfg with training set and updated initial guess from the mfgfix training set fit\n",
    "    cv_mfg_best, cv_mfg_cov = curve_fit(Mfg, training_set[:,0], training_set[:,1], sigma=training_set[:,2],\n",
    "                                        p0=cv_initial_guess_mfg, bounds=param_bounds_mfg)\n",
    "\n",
    "    # Get the chi2 from the validation set\n",
    "    cv_mfg_chi2 = chi2_model(validation_set, Mfg, cv_mfg_best)\n",
    "    # Get the loglike\n",
    "    cv_mfg_loglike = -0.5*len(data)*np.log(2.0*np.pi) - np.sum(np.log(data[:,2])) - 0.5*cv_mfg_chi2\n",
    "\n",
    "\n",
    "    cv_N = len(training_set) # number of points in the training set\n",
    "\n",
    "    # AIC and BIC for the validation runs\n",
    "    cv_m0_AIC = get_AIC(cv_m0_loglike, m0_k)\n",
    "    cv_m0_BIC = get_BIC(cv_m0_loglike, m0_k, cv_N)\n",
    "    cv_mf_AIC = get_AIC(cv_mf_loglike, mf_k)\n",
    "    cv_mf_BIC = get_BIC(cv_mf_loglike, mf_k, cv_N)\n",
    "    cv_mg_AIC = get_AIC(cv_mg_loglike, mg_k)\n",
    "    cv_mg_BIC = get_BIC(cv_mg_loglike, mg_k, cv_N)\n",
    "    cv_mfg_AIC = get_AIC(cv_mfg_loglike, mfg_k)\n",
    "    cv_mfg_BIC = get_BIC(cv_mfg_loglike, mfg_k, cv_N)\n",
    "    \n",
    "    # formatting return\n",
    "    r_m0 = np.array([cv_m0_chi2, cv_m0_BIC, cv_m0_AIC])\n",
    "    r_mf = np.array([cv_mf_chi2, cv_mf_BIC, cv_mf_AIC])\n",
    "    r_mg = np.array([cv_mg_chi2, cv_mg_BIC, cv_mg_AIC])\n",
    "    r_mfg = np.array([cv_mfg_chi2, cv_mfg_BIC, cv_mfg_AIC])\n",
    "    return np.vstack((r_m0, r_mf, r_mg, r_mfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV many many times\n",
    "cv_runs = 50\n",
    "\n",
    "# roughly 20% of our dataset\n",
    "p = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n",
      "(12, 15, 15, 18, 191)\n"
     ]
    }
   ],
   "source": [
    "cv_m0_stack_list = []\n",
    "cv_mf_stack_list = []\n",
    "cv_mg_stack_list = []\n",
    "cv_mfg_stack_list = []\n",
    "\n",
    "for i in range(cv_runs):\n",
    "    cv_results = do_cv_on_all_models(p)\n",
    "    cv_m0_stack_list.append(cv_results[0])\n",
    "    cv_mf_stack_list.append(cv_results[1])\n",
    "    cv_mg_stack_list.append(cv_results[2])\n",
    "    cv_mfg_stack_list.append(cv_results[3])\n",
    "\n",
    "cv_m0_stack = np.vstack((cv_m0_stack_list))\n",
    "cv_mf_stack = np.vstack((cv_mf_stack_list))\n",
    "cv_mg_stack = np.vstack((cv_mg_stack_list))\n",
    "cv_mfg_stack = np.vstack((cv_mfg_stack_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  92.34107796,  900.53295887,  861.50567773])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_m0_stack, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  82.57127227,  906.51997346,  857.73587204])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_mf_stack, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  83.02730829,  906.97600948,  858.19190806])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_mg_stack, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  73.35419176,  913.05971324,  854.51879153])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_mfg_stack, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
